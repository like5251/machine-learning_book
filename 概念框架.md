
## 一、基本术语
### 1.1 定义
- 数据集（data set）：记录/样本/实例的集合
    - 训练集（Training set）:用于模型训练的数据集
    >A set of examples used for learning, which is to fit the parameters [i.e., weights] of the classifier.
    - 验证集（Validation set）:用于模型评估的数据集
    > A set of examples used to tune the parameters [i.e., architecture, not weights] of a classifier, for example to choose the number of hidden units in a neural network.
    - 测试集（Test set）:用于在实际场景进行预测的数据集
    > A set of examples used only to assess the performance [generalization] of a fully specified classifier. 

- 输入空间：由属性/特征张成的空间。又称为样本空间（sample space）、特征空间（feature space）。
    - 属性/特征：反映对象在某方面的性质的事项称为对象的特征
    - 特征值：特征上的取值
    - 样本(sample)：每个具体的输入/记录称为一个样本或实例（instance），通常用特征向量（feature vector）来表示
    - 维数：样本中特征个数称为样本的维度
- 输出空间：由目标标记张成的空间，也叫标记空间（label space）
    - 标记（label）：样本的标记信息，作为每个样本的输出信息
    - 样例（example）：带有标记信息的样本称为一个样例
- 假设空间（hypothesis space）：由输入空间到输出空间的映射的集合，即由假设模型所构成的集合。学习的过程就是在假设空间进行搜索，找到与训练集匹配（fit）的假设模型的过程。

- 泛化能力（generalization）：学得模型适用于新样本的能力。泛化能力强的模型能够更好的适用于整个样本空间，事实上评判一个模型好坏的核心标准就是它的泛化能力。
- 独立同分布（independent and identically distributed ）:通常假设样本空间中全体样本都相互独立，且服从一个共同的未知分布。只有在独立同分布的前提下才能够使用样本来预测整体。

### 1.2 表示
- 数据集通常用数据表来存储：

![](/assets/dataset.png)

- 代数表示：
    - 数据集：$$D = \{(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{m},y_{m})\}$$，m是数据集中样例个数，$$(x_{i},y_{i})$$代表第i个样例，$$x_{i}$$代表第i个样例的特征向量，$$y_{i}$$代表第i个样例的标记
    - 特征向量：$$x_{i}=\{x_{i1}, x_{i2},...,x_{id}\}$$，d是样本维度，$$x_{ij}$$代表第i个样本中的第j个特征值
$$
D = \begin{bmatrix}
x_{11} &x_{12}  &...  &x_{1d} &y_{1}  \\ 
x_{21} &x_{22}  &...  &x_{2d} &y_{2} \\ 
.&. &...  &. &.\\ 
.&. &...  &. &. \\ 
x_{m1} &x_{m2}  &...  &x_{md} &y_{m} 
\end{bmatrix}
$$

## 二、归纳偏好
> 没有免费午餐定理（No Free Lunch，NFL）：如果所有假设都等可能为真，则任何学习算法的期望性能都和胡乱猜测差不多。

> 归纳偏好：对某种假设的特殊偏好。任何有效的机器学习算法必有其归纳偏好，否则将无法产生任何确定的结果。

> 空泛的说哪种学习算法好毫无意义，算法的好坏取决于归纳偏好是否能很好的匹配所要解决的问题。

翻译成大白话就是，如果所有假设成立的可能性都一样，那就不用做什么假设了，直接猜就好了；因此如果要使用机器学习算法来解决问题，就必须在诸多假设中做出选择；假设本身没有好坏，只有当假设能够和具体问题相匹配时才是好的假设。

## 机器学习分类
### 按标记类型分类
- 有监督学习（supervised learning）：标记空间事先已知。监督学习又可根据标记类型来分成分类和回归问题：
    - 分类问题（classification）：标记类型是标称型，目标变量只在有限目标集中取值。
    - 回归问题（regression）：标记类型是数值型，目标变量可以再无限数值集合中取值
- 无监督学习（unsupervised learning）：标记空间事先未知
    - 聚类：
    - 降维：

> - 半监督学习（Semi-Supervised Learning，SSL）：监督学习与无监督学习相结合的一种学习方法
> - 强化学习（reinforcement learning）：从环境到行为映射的学习，在传统的机器学习分类中没有提到过强化学习

![](/assets/cf.png)

### 判别模型和生成模型
监督学习方法又可分为生成方法和判别方法，所学到的模型分别为生成模型和判别模型：
- 生成模型（generative model）：由数据学习联合概率分布$$P(X,Y)$$，然后求出条件概率分布$$P(Y|X)$$，作为预测的模型。因为给定了X后可以通过联合概率分布来生成Y，故称生成方法。
- 判别方法（discriminative model）：由数据直接学习决策函数$$f(X)$$或条件概率分布$$P(Y|X)$$作为预测的模型。

![](/assets/p.png)

## 机器学习的基本过程




