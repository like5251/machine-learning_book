# 集成学习
> 集成学习（ensemble，"昂森宝"，或者aggregation）：通过组合多个学习器以获取更好的泛化性能。

## 一、集成学习的理论基础
集成学习的两个步骤：
1. 产生一组“弱学习器” ：$$g_{1}(\boldsymbol{x})$$、$$g_{2}(\boldsymbol{x})$$、$$g_{3}(\boldsymbol{x})$$......
2. 按照某种规则将弱分类器组合起来：$$G(\boldsymbol{x})=\sum_{t=1}^{T}\alpha_{t} g_{t}(\boldsymbol{x})$$

### 1. 产生弱分类器的方式
> 弱分类器：泛化性能略优于随机猜测的学习器称为弱学习器。它有两层含义：
1. 弱：虽然从理论上说使用弱分类器集成足以获得好的性能，但在实践中为了减少学习器的数量，人们往往会使用比较强的学习器。
2. 强：所选用的弱分类器必须得比随机猜测要好（如二分类误分率>0.5），这样才能“强强联合”，否则该学习器会成为集成中的“害群之马”，应被过滤掉。

#### 1.1 获取弱分类器的方法
1. 基于不同的模型：$$g_{1}\in H_{1},g_{2}\in H_{2},...,g_{T}\in H_{T}$$，如通过逻辑回归和随机森林获取两个不同模型；
2. 基于的不同超参数：如通过设置随机森林不同的超参数来得到多个随机森林模型；
3. 基于不同的训练数据：如bagging的方法（有放回地均匀采样）、随机森林（有放回地均匀采样）、Adaboost（按照误分率改变样本权重）
4. 基于随机算法：如遗传编程、选取不同的seeds等

#### 1.2 集成的原则
集成原则：要获取好的集成，每个分类器应”好而不同“。

1. 好：每个分类器要有一定”准确性“，至少要好于随机猜测；
2. 不同：应保证分类器的”多样性“，通过上述不同的方式获取到区分度较高的基本分类器；

假设各分类器相互独立，则集成错误率随基本学习器数量的增加而指数级下降：

$$
P(G(x)\neq f(x))\leqslant exp(-\frac{1}{2}T(1-2\varepsilon )^2)
$$

”准确性“和”独立性“的矛盾：当准确性很高以后，要增加准确性就得牺牲掉多样性，如何产生”好而不同“的多个学习器正是集成学习的核心。

### 2. 弱分类器集成的方式
> 假设我们已经获取到了多个基本学习器$$g_{1}(\boldsymbol{x})$$、$$g_{2}(\boldsymbol{x})$$、$$g_{3}(\boldsymbol{x})$$......，通常有以下几种方式来进行集成：
1. select:选取验证误差最小的模型作为最终模型；
2. uniform blending(voting)：取每个模型预测结果的的算术平均作为最终预测结果；
3. Linear blending：取所有模型预测结果的加权平均作为最终预测结果；
4. stacking：根据输入有条件地进行组合

#### select
select：在所有模型中选取验证误差最小的模型作为最终模型:
$$
G(x)=g_{*} with t_{*}=argmin(E_{val}(g^-_{t}))
$$

- 使用方法：一般会在训练集上训练多个模型，然后在测试集上选择其中泛化选择最好的模型；
- 第一名中的第一名：如果每个模型都是它所在假设空间中的第一名，那么select就是在第一名中选择第一名；
- 强人领导：select方法依赖于备选模型中要有一个强分类器；如果是在一群弱学习器中进行select则完全没有意义；


#### uniform blending(voting)

$$
G(x)=sign(\sum_{t=1}^{T}g_{t}(x))
$$

- 集体智慧+民主投票
- 对于分类问题：

#### Linear blending

$$
G(x)=sign(\sum_{t=1}^{T} \alpha _{t}\cdot g_{t}(x)) with \alpha _{t}\geq 0
$$

- select和uniformly是Linear blending的特例


#### stacking

$$
G(x)=sign(\sum_{t=1}^{T} q _{t}(x)\cdot g_{t}(x)) withq_{t}(x)\geq 0
$$

- 包括前面所有的情形； 


### 为什么集成学习是有效的
![](/assets/A0B3B758-A959-469E-A5A2-05AD2ECB9704.png)

- 机器学习——开车
- 增加训练程度——油门——降低偏差——串行集成相当于做了特征转换
- 降低训练程度——刹车——降低方差——并行集成相当于做了正则化















