## 决策树模型
> 决策树：决策树是一种对实例进行分类/回归的树形结构。每个内部节点表示一次特征测试，每条边表示特征测试结果，每个叶节点表示一种最终决策结果，从根节点到叶节点的每条路径表示一条判定规则，对每个实例都存在唯一的路径与之对应。

1. if-then规则视角：决策树可看做是一个if-then规则的集合。每条规则唯一对应一条从根节点到叶节点的路径，内部节点是规则的条件，叶节点是规则的结论。if-then规则集是一种stacking方法——按条件为每个模型赋权。
$$
G(x) = \sum_{t=1}^{T}q_{t}(x)\cdot g_{t}(x)\\
G(x) = \sum_{t=1}^{T}I(x \text{ on path t})\cdot leaf_{t}(x)
$$

2. 特征空间视角：决策树也可以看做是在特征空间中的条件概率分布。按各维特征的不同取值将特征空间划分为互不相交的区域$$R_{1},R_{2}...$$，在每个区域定义一个类的概率分布就构成可一个条件概率分布$$P(y|X)$$。
![](/assets/image00381.jpeg)

3. 递归视角：决策树可以进行递归定义
    - $$G(x)$$全树模型：x在决策树中的判定结果
    - $$b(x)$$分支条件：x在某特征上的测试结果
    - $$G_{c}(x)$$子树模型：x在子树c上的判定结果
$$
G(x) = \sum_{t=1}^{T}I(b(x)=c)\cdot G_{c}(x)
$$

## 决策树学习
决策树学习包括两个部分：

1. 决策树生成：
    1. 退出条件：D中yn都相同、D中xn都相同、D为空、A为空、信息增益或损失下降不足某个阈值；
    2. 基本模型：分类树取D中样本最多的类别y来标记叶节点，回归树取D中样本标记的均值来标记叶节点；
    3. 特征选择：ID3（分类树-选取信息增益最大特征）、C4.5（分类树-选取信息增益率最大的特征）、CART（分类树-选取某特征的某划分点使得基尼系数最小/回归树-平方损失最小）
    4. 区域划分：如果是离散特征，ID3和C4.5是按选中的特征的每个取值来划分数据集，CART是按特征是否取某个取值，将数据集进行二分；如果是连续值，先对特征进行离散化，然后选取某个阈值对数据进行二分，使得信息增益或者平方损失最小。
    5. 迭代组合：都一样
2. 决策树剪枝

### 决策树生成
决策树生成的一般算法如下：

```python
def DT(D,A):
    if can't braching:
        return gt(x)
    else:
        特征选择：确定分支条件b(x)
        区域划分：按照分支条件划分数据集Dc={(xn,yn)|b(xn=c)}
        在每个区域Dc递归构建子树：Gc=DT(Dc,{A-Ag})
        return G(x) = ∑ I(b(x)=c)Gc(x)
```

### 1. ID3算法
核心：以信息增益作为特征选择的标准、分类树

输入：训练集D，特征集A，阈值$$\epsilon $$

输出：决策树T

1. 如果D中所有样本的类别y都一样，或所有x都一样，或A为空，则返回单节点树T，并将D中样本数最多的类别作为T的类标记；
2. 否则计算各个特征对D中标记的信息增益，选择信息增益最大的特征$$A_{g}$$；
    1. 如果$$A_{g} < \epsilon$$，则返回单节点树T，D中样本数最多的类别作为T的类标记；
    2. 否则，按照特征$$A_{g}$$的每一可能取值将数据集D划分为若干子集$$D_{c}$$，对每个非空子集$$D_{c}$$，以$${A-A_{g}}$$为特征集，递归调用以上过程，构建子树$$T_{c}$$，对每个空子集，则构建单节点子树$$T_{c}$$，并将D中样本数最多的类别作为$$T_{c}$$的标记。
    3. 将所有子树组合为最终的决策树：$$T = \sum_{c=1}^{C}I(b(x)=c)\cdot T_{c}$$



### 2. C4.5


### 3. CART

### 决策树剪枝

通用算法：

$$
G(x) = \sum_{t=1}^{T}I(b(x)=c)\cdot G_{c}(x)
$$


- 输入：训练数据集D，特征集A，阈值$$\epsilon $$；
- 输出：决策树T

（1）如果达到退出条件，返回基本模型；
（2）否则，选择特征和切分方式对D进行划分，如果Dv为空
    
 
     
    
       
退出条件包括：
1. D中所有样本的y都相同——把y作为叶节点返回
2. D中所有样本的X都相同——把X中所含样本最多的类别y最为叶节点返回
3. D为空，以父节点中样本数最多的类别y作为叶节点返回
4. 特征为空，以当前D中样本数最多的类别y作为叶节点返回




















